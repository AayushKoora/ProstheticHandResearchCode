{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b07549b9",
   "metadata": {},
   "source": [
    "Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e45f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, FunctionTransformer, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8910a03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_nonnegative(X):\n",
    "  return np.clip(X, 0, None)\n",
    "\n",
    "def shift_function(X):\n",
    "  min_val = np.min(X)\n",
    "\n",
    "  if min_val < 0:\n",
    "    X_shifted = X - min_val + 1e-6\n",
    "  else:\n",
    "    X_shifted = X\n",
    "  \n",
    "  return X_shifted\n",
    "\n",
    "def results(pipe, x_train, x_test, y_train_scaled, y_test_scaled, y_scaler):\n",
    "  pipe.fit(x_train, y_train_scaled)\n",
    "  y_pred_scaled = pipe.predict(x_test)\n",
    "\n",
    "  y_pred_original = y_scaler.inverse_transform(y_pred_scaled)\n",
    "  y_test_original_check = y_scaler.inverse_transform(y_test_scaled)\n",
    "\n",
    "  rmse = np.sqrt(mean_squared_error(y_test_original_check, y_pred_original))\n",
    "  r2 = r2_score(y_test_original_check, y_pred_original)\n",
    "\n",
    "  return rmse, r2\n",
    "\n",
    "x, y = np.loadtxt(\"X_all.csv\", delimiter = ','), np.loadtxt(\"Y_all.csv\", delimiter = ',')\n",
    "subject_ids = np.loadtxt(\"subject_ids.csv\", delimiter=\",\").astype(int)\n",
    "\n",
    "subject_results = {\n",
    "    'subject': [], 'n_train': [], 'n_test': [],\n",
    "    'ns_lr_rmse': [], 'ns_lr_r2': [],\n",
    "    's_lr_rmse': [], 's_lr_r2': [],\n",
    "    'ns_rf_rmse': [], 'ns_rf_r2': [],\n",
    "    's_rf_rmse': [], 's_rf_r2': [],\n",
    "    'ns_svm_rmse': [], 'ns_svm_r2': [],\n",
    "    's_svm_rmse': [], 's_svm_r2': []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f75f1bb",
   "metadata": {},
   "source": [
    "Baseline Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa5d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in np.unique(subject_ids):\n",
    "    print(f\"Subject {subject}\")\n",
    "\n",
    "    mask = subject_ids == subject\n",
    "    x_subject = x[mask]\n",
    "    y_subject = y[mask]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x_subject, y_subject, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    y_train_original = y_train.copy()\n",
    "    y_test_original = y_test.copy()\n",
    "\n",
    "    lr_y_scaler = StandardScaler()\n",
    "    lr_y_train = lr_y_scaler.fit_transform(y_train)\n",
    "    lr_y_test = lr_y_scaler.transform(y_test)\n",
    "\n",
    "    y_scaler = RobustScaler()\n",
    "    y_train = y_scaler.fit_transform(y_train)\n",
    "    y_test = y_scaler.transform(y_test)\n",
    "\n",
    "    # Non-Synergy LinearRegression\n",
    "    ns_lr_pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', MultiOutputRegressor(LinearRegression()))\n",
    "    ])\n",
    "    ns_lr_rmse, ns_lr_r2 = results(ns_lr_pipe, x_train, x_test, lr_y_train, lr_y_test, lr_y_scaler)\n",
    "\n",
    "    # Synergy LinearRegression 48\n",
    "    s_lr_pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('shift', FunctionTransformer(shift_function)),\n",
    "        ('nmf', NMF(n_components = 30, random_state = 42, max_iter = 5000, init='nndsvda')),\n",
    "        ('model', MultiOutputRegressor(LinearRegression()))\n",
    "    ])\n",
    "    s_lr_rmse, s_lr_r2 = results(s_lr_pipe, x_train, x_test, lr_y_train, lr_y_test, lr_y_scaler)\n",
    "\n",
    "    # Non-Synergy RandomForestRegressor\n",
    "    ns_rf_pipe = Pipeline([\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('model', RandomForestRegressor(\n",
    "            max_features = 'sqrt',\n",
    "            max_depth = 7,\n",
    "            min_samples_split = 15,\n",
    "            min_samples_leaf = 8,\n",
    "            n_estimators = 300,\n",
    "            random_state = 42,\n",
    "            n_jobs=-1)),\n",
    "    ])\n",
    "    ns_rf_rmse, ns_rf_r2 = results(ns_rf_pipe, x_train, x_test, y_train, y_test, y_scaler)\n",
    "\n",
    "    # Synergy RandomForestRegressor 48\n",
    "    s_rf_pipe = Pipeline([\n",
    "        ('scaler', MinMaxScaler(feature_range = (0, 1))),\n",
    "        ('clip', FunctionTransformer(ensure_nonnegative)),\n",
    "        ('nmf', NMF(n_components = 40, random_state = 42, max_iter = 5000, init='nndsvda')),\n",
    "        ('model', RandomForestRegressor(\n",
    "            max_features = 'sqrt',\n",
    "            max_depth = 7,\n",
    "            min_samples_split = 15,\n",
    "            min_samples_leaf = 8,\n",
    "            n_estimators = 300,\n",
    "            random_state = 42,\n",
    "            n_jobs=-1)),\n",
    "    ])\n",
    "    s_rf_rmse, s_rf_r2 = results(s_rf_pipe, x_train, x_test, y_train, y_test, y_scaler)\n",
    "\n",
    "    # Non-Synergy SupportVectorRegression\n",
    "    ns_svm_pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', MultiOutputRegressor(SVR(C = 10, epsilon = 0.1, kernel = 'linear'))),\n",
    "    ])\n",
    "    ns_svm_rmse, ns_svm_r2 = results(ns_svm_pipe, x_train, x_test, y_train, y_test, y_scaler)\n",
    "\n",
    "    # Synergy SupportVectorRegression 40\n",
    "    s_svm_pipe = Pipeline([\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('clip', FunctionTransformer(ensure_nonnegative)),\n",
    "        ('nmf', NMF(n_components = 35, random_state = 42, max_iter = 5000)),\n",
    "        ('model', MultiOutputRegressor(SVR(C = 10, epsilon = 0.1, kernel = 'linear'))),\n",
    "    ])\n",
    "    s_svm_rmse, s_svm_r2 = results(s_svm_pipe, x_train, x_test, y_train, y_test, y_scaler)\n",
    "\n",
    "    subject_results['subject'].append(subject)\n",
    "    subject_results['n_train'].append(len(x_train))\n",
    "    subject_results['n_test'].append(len(x_test))\n",
    "    subject_results['ns_lr_rmse'].append(ns_lr_rmse)\n",
    "    subject_results['ns_lr_r2'].append(ns_lr_r2)\n",
    "    subject_results['s_lr_rmse'].append(s_lr_rmse)\n",
    "    subject_results['s_lr_r2'].append(s_lr_r2)\n",
    "    subject_results['ns_rf_rmse'].append(ns_rf_rmse)\n",
    "    subject_results['ns_rf_r2'].append(ns_rf_r2)\n",
    "    subject_results['s_rf_rmse'].append(s_rf_rmse)\n",
    "    subject_results['s_rf_r2'].append(s_rf_r2)\n",
    "    subject_results['ns_svm_rmse'].append(ns_svm_rmse)\n",
    "    subject_results['ns_svm_r2'].append(ns_svm_r2)\n",
    "    subject_results['s_svm_rmse'].append(s_svm_rmse)\n",
    "    subject_results['s_svm_r2'].append(s_svm_r2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY: AVERAGE ACROSS ALL SUBJECTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results_df = pd.DataFrame(subject_results)\n",
    "\n",
    "summary_data = []\n",
    "for model_name, rmse_col, r2_col in [\n",
    "    ('NS LinearRegression', 'ns_lr_rmse', 'ns_lr_r2'),\n",
    "    ('S LinearRegression', 's_lr_rmse', 's_lr_r2'),\n",
    "    ('NS RandomForest', 'ns_rf_rmse', 'ns_rf_r2'),\n",
    "    ('S RandomForest', 's_rf_rmse', 's_rf_r2'),\n",
    "    ('NS SupportVectorMachine', 'ns_svm_rmse', 'ns_svm_r2'),\n",
    "    ('S SupportVectorMachine', 's_svm_rmse', 's_svm_r2')\n",
    "]:\n",
    "    rmse_mean = results_df[rmse_col].mean()\n",
    "    rmse_std = results_df[rmse_col].std()\n",
    "    r2_mean = results_df[r2_col].mean()\n",
    "    r2_std = results_df[r2_col].std()\n",
    "    \n",
    "    summary_data.append([\n",
    "        model_name,\n",
    "        rmse_mean,\n",
    "        rmse_std,\n",
    "        r2_mean,\n",
    "        r2_std\n",
    "    ])\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data, \n",
    "                          columns=['Model', 'Mean RMSE', 'Std RMSE', 'Mean R2', 'Std R2'])\n",
    "\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac0dd60",
   "metadata": {},
   "source": [
    "Optimal Synergy Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00f2938",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components_range = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "\n",
    "sweep_results = []\n",
    "\n",
    "# Loop through each subject\n",
    "for subject in np.unique(subject_ids):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing Subject {subject}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Get subject-specific data\n",
    "    mask = subject_ids == subject\n",
    "    x_subject = x[mask]\n",
    "    y_subject = y[mask]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x_subject, y_subject, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Scale y data\n",
    "    lr_y_scaler = StandardScaler()\n",
    "    lr_y_train = lr_y_scaler.fit_transform(y_train.copy())\n",
    "    lr_y_test = lr_y_scaler.transform(y_test.copy())\n",
    "\n",
    "    y_scaler = RobustScaler()\n",
    "    y_train_scaled = y_scaler.fit_transform(y_train.copy())\n",
    "    y_test_scaled = y_scaler.transform(y_test.copy())\n",
    "\n",
    "    # Define base pipelines\n",
    "    base_s_lr_pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('shift', FunctionTransformer(shift_function)),\n",
    "        ('nmf', NMF(n_components=48, random_state=42, max_iter=5000, init='nndsvda')),\n",
    "        ('model', MultiOutputRegressor(LinearRegression()))\n",
    "    ])\n",
    "\n",
    "    base_s_rf_pipe = Pipeline([\n",
    "        ('scaler', MinMaxScaler(feature_range=(0, 1))),\n",
    "        ('clip', FunctionTransformer(ensure_nonnegative)),\n",
    "        ('nmf', NMF(n_components=48, random_state=42, max_iter=5000, init='nndsvda')),\n",
    "        ('model', RandomForestRegressor(\n",
    "            max_features='sqrt', max_depth=7,\n",
    "            min_samples_split=15, min_samples_leaf=8,\n",
    "            n_estimators=300, random_state=42, n_jobs=-1)),\n",
    "    ])\n",
    "\n",
    "    base_s_svm_pipe = Pipeline([\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('clip', FunctionTransformer(ensure_nonnegative)),\n",
    "        ('nmf', NMF(n_components=40, random_state=42, max_iter=5000)),\n",
    "        ('model', MultiOutputRegressor(SVR(C=10, epsilon=0.1, kernel='rbf'))),\n",
    "    ])\n",
    "\n",
    "    # Models config with proper y data and scalers\n",
    "    synergy_models = {\n",
    "        'S LinearRegression': {\n",
    "            'base_pipe': base_s_lr_pipe,\n",
    "            'y_train': lr_y_train,\n",
    "            'y_test': lr_y_test,\n",
    "            'y_scaler': lr_y_scaler\n",
    "        },\n",
    "        'S RandomForestRegressor': {\n",
    "            'base_pipe': base_s_rf_pipe,\n",
    "            'y_train': y_train_scaled,\n",
    "            'y_test': y_test_scaled,\n",
    "            'y_scaler': y_scaler\n",
    "        },\n",
    "        'S SupportVectorRegression': {\n",
    "            'base_pipe': base_s_svm_pipe,\n",
    "            'y_train': y_train_scaled,\n",
    "            'y_test': y_test_scaled,\n",
    "            'y_scaler': y_scaler\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Sweep through models and components\n",
    "    for model_name, model_config in synergy_models.items():\n",
    "        print(f\"\\n  Sweeping {model_name}\")\n",
    "\n",
    "        for n_comp in n_components_range:\n",
    "            print(f\"    N_Components: {n_comp}...\", end=\" \")\n",
    "            \n",
    "            # Clone and configure pipeline\n",
    "            pipe = clone(model_config['base_pipe'])\n",
    "            pipe.named_steps['nmf'].n_components = n_comp\n",
    "\n",
    "            # Train\n",
    "            train_start = time.time()\n",
    "            pipe.fit(x_train, model_config['y_train'])\n",
    "            train_time = time.time() - train_start\n",
    "\n",
    "            # Inference timing\n",
    "            inference_times = []\n",
    "            for _ in range(10):\n",
    "                inf_start = time.time()\n",
    "                y_pred = pipe.predict(x_test)\n",
    "                inference_times.append(time.time() - inf_start)\n",
    "            avg_inference_time = np.mean(inference_times)\n",
    "\n",
    "            # Transform predictions back to original scale\n",
    "            y_pred_original = model_config['y_scaler'].inverse_transform(y_pred)\n",
    "            y_test_original = model_config['y_scaler'].inverse_transform(model_config['y_test'])\n",
    "                \n",
    "            # Calculate metrics\n",
    "            rmse = np.sqrt(mean_squared_error(y_test_original, y_pred_original))\n",
    "            r2 = r2_score(y_test_original, y_pred_original)\n",
    "\n",
    "            # Model size\n",
    "            model_bytes = pickle.dumps(pipe)\n",
    "            model_size_mb = len(model_bytes) / (1024 * 1024)\n",
    "\n",
    "            sweep_results.append({\n",
    "                'Subject': subject,\n",
    "                'Model': model_name,\n",
    "                'n_components': n_comp,\n",
    "                'rmse': rmse,\n",
    "                'r2': r2,\n",
    "                'train_time_s': train_time,\n",
    "                'inference_time_s': avg_inference_time,\n",
    "                'model_size_mb': model_size_mb\n",
    "            })\n",
    "            \n",
    "            print(f\"RMSE={rmse:.4f}, R²={r2:.4f}\")\n",
    "\n",
    "# Create DataFrame with all subjects\n",
    "sweep_df = pd.DataFrame(sweep_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RAW SWEEP DATA (ALL SUBJECTS)\")\n",
    "print(\"=\"*80)\n",
    "print(sweep_df.head(20))\n",
    "\n",
    "# Calculate averages across subjects\n",
    "sweep_avg = sweep_df.groupby(['Model', 'n_components']).agg({\n",
    "    'rmse': ['mean', 'std'],\n",
    "    'r2': ['mean', 'std'],\n",
    "    'train_time_s': ['mean', 'std'],\n",
    "    'inference_time_s': ['mean', 'std'],\n",
    "    'model_size_mb': ['mean', 'std']\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "sweep_avg.columns = ['_'.join(col).strip('_') for col in sweep_avg.columns.values]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AVERAGED SWEEP RESULTS (ACROSS ALL 7 SUBJECTS)\")\n",
    "print(\"=\"*80)\n",
    "print(sweep_avg)\n",
    "\n",
    "# Save results\n",
    "sweep_df.to_csv('component_sweep_all_subjects.csv', index=False)\n",
    "sweep_avg.to_csv('component_sweep_averaged.csv', index=False)\n",
    "\n",
    "print(\"\\n✓ Component sweep complete!\")\n",
    "print(f\"  Total experiments: {len(sweep_df)} ({len(sweep_df) // 7} per subject × 7 subjects)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503bbc65",
   "metadata": {},
   "source": [
    "Model Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fbc601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_noise(signal, snr_db):\n",
    "    signal_power = np.mean(signal ** 2)\n",
    "    noise_power = signal_power / (10 ** (snr_db / 10))\n",
    "    noise = np.random.normal(0, np.sqrt(noise_power), signal.shape)\n",
    "    return signal + noise\n",
    "\n",
    "snr_list = [100, 80, 60, 40, 20]\n",
    "model_names = ['NS RandomForestRegressor', 'S RandomForestRegressor', \n",
    "               'NS SupportVectorRegression', 'S SupportVectorRegression']\n",
    "\n",
    "# Store results for ALL subjects\n",
    "all_noise_results = []\n",
    "\n",
    "# Loop through each subject\n",
    "for subject in np.unique(subject_ids):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Testing Noise Robustness - Subject {subject}\")\n",
    "    print('='*50)\n",
    "    \n",
    "    # Get subject-specific data\n",
    "    mask = subject_ids == subject\n",
    "    x_subject = x[mask]\n",
    "    y_subject = y[mask]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x_subject, y_subject, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Scale y data (using RobustScaler for RF and SVM)\n",
    "    y_scaler = RobustScaler()\n",
    "    y_train_scaled = y_scaler.fit_transform(y_train.copy())\n",
    "    y_test_scaled = y_scaler.transform(y_test.copy())\n",
    "\n",
    "    # Define fresh pipelines for this subject\n",
    "    ns_rf_pipe = Pipeline([\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('model', RandomForestRegressor(\n",
    "            max_features='sqrt', max_depth=7,\n",
    "            min_samples_split=15, min_samples_leaf=8,\n",
    "            n_estimators=300, random_state=42, n_jobs=-1)),\n",
    "    ])\n",
    "\n",
    "    s_rf_pipe = Pipeline([\n",
    "        ('scaler', MinMaxScaler(feature_range=(0, 1))),\n",
    "        ('clip', FunctionTransformer(ensure_nonnegative)),\n",
    "        ('nmf', NMF(n_components=40, random_state=42, max_iter=5000, init='nndsvda')),\n",
    "        ('model', RandomForestRegressor(\n",
    "            max_features='sqrt', max_depth=7,\n",
    "            min_samples_split=15, min_samples_leaf=8,\n",
    "            n_estimators=300, random_state=42, n_jobs=-1)),\n",
    "    ])\n",
    "\n",
    "    ns_svm_pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', MultiOutputRegressor(SVR(C=10, epsilon=0.1, kernel='rbf'))),\n",
    "    ])\n",
    "\n",
    "    s_svm_pipe = Pipeline([\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('clip', FunctionTransformer(ensure_nonnegative)),\n",
    "        ('nmf', NMF(n_components=35, random_state=42, max_iter=5000)),\n",
    "        ('model', MultiOutputRegressor(SVR(C=10, epsilon=0.1, kernel='rbf'))),\n",
    "    ])\n",
    "\n",
    "    pipe_list = [ns_rf_pipe, s_rf_pipe, ns_svm_pipe, s_svm_pipe]\n",
    "\n",
    "    # Fit all pipelines on THIS subject's training data\n",
    "    for pipe in pipe_list:\n",
    "        pipe.fit(x_train, y_train_scaled)\n",
    "\n",
    "    # Test with different noise levels\n",
    "    for snr_db in snr_list:\n",
    "        print(f\"  Testing SNR = {snr_db} dB\")\n",
    "        x_test_noise = gaussian_noise(x_test, snr_db)\n",
    "\n",
    "        for pipe, model_name in zip(pipe_list, model_names):\n",
    "            y_pred_scaled = pipe.predict(x_test_noise)\n",
    "            \n",
    "            # Transform back to original scale\n",
    "            y_pred_original = y_scaler.inverse_transform(y_pred_scaled)\n",
    "            y_test_original = y_scaler.inverse_transform(y_test_scaled)\n",
    "            \n",
    "            # Calculate RMSE and R² on original scale\n",
    "            rmse_noise = np.sqrt(mean_squared_error(y_test_original, y_pred_original))\n",
    "            r2_noise = r2_score(y_test_original, y_pred_original)\n",
    "            \n",
    "            all_noise_results.append({\n",
    "                'Subject': subject,\n",
    "                'SNR (dB)': snr_db,\n",
    "                'Model': model_name,\n",
    "                'RMSE': rmse_noise,\n",
    "                'R2': r2_noise\n",
    "            })\n",
    "\n",
    "# Create DataFrame with ALL subjects\n",
    "noise_df_all = pd.DataFrame(all_noise_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RAW NOISE DATA (ALL SUBJECTS)\")\n",
    "print(\"=\"*80)\n",
    "print(noise_df_all)\n",
    "\n",
    "# Calculate AVERAGE across all subjects\n",
    "noise_df = noise_df_all.groupby(['SNR (dB)', 'Model']).agg({\n",
    "    'RMSE': ['mean', 'std'],\n",
    "    'R2': ['mean', 'std']\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "noise_df.columns = ['SNR (dB)', 'Model', 'RMSE', 'RMSE_std', 'R2', 'R2_std']\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AVERAGED NOISE ROBUSTNESS (ACROSS ALL 7 SUBJECTS)\")\n",
    "print(\"=\"*80)\n",
    "print(noise_df)\n",
    "\n",
    "# Verify all models are present\n",
    "print(\"\\nUnique models in noise_df:\", noise_df['Model'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dca6e7",
   "metadata": {},
   "source": [
    "Training Efficiency and Sample Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801c6020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "train_sizes = [0.10, 0.25, 0.50, 0.75, 1.00]  # Percentages\n",
    "n_components_list = [5, 20, 35, 50]\n",
    "\n",
    "all_training_results = []\n",
    "print(\"Starting Training Efficiency Analysis...\")\n",
    "\n",
    "for subject in np.unique(subject_ids):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Training Efficiency Analysis - Subject {subject}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Get subject-specific data\n",
    "    mask = subject_ids == subject\n",
    "    x_subject = x[mask]\n",
    "    y_subject = y[mask]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x_subject, y_subject, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Scale y data\n",
    "    lr_y_scaler = StandardScaler()\n",
    "    lr_y_train = lr_y_scaler.fit_transform(y_train.copy())\n",
    "    lr_y_test = lr_y_scaler.transform(y_test.copy())\n",
    "\n",
    "    y_scaler = RobustScaler()\n",
    "    y_train_scaled = y_scaler.fit_transform(y_train.copy())\n",
    "    y_test_scaled = y_scaler.transform(y_test.copy())\n",
    "\n",
    "    # Define pipelines for this subject\n",
    "    s_lr_pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('shift', FunctionTransformer(shift_function)),\n",
    "        ('nmf', NMF(n_components=48, random_state=42, max_iter=5000, init='nndsvda')),\n",
    "        ('model', MultiOutputRegressor(LinearRegression()))\n",
    "    ])\n",
    "\n",
    "    s_rf_pipe = Pipeline([\n",
    "        ('scaler', MinMaxScaler(feature_range=(0, 1))),\n",
    "        ('clip', FunctionTransformer(ensure_nonnegative)),\n",
    "        ('nmf', NMF(n_components=48, random_state=42, max_iter=5000, init='nndsvda')),\n",
    "        ('model', RandomForestRegressor(\n",
    "            max_features='sqrt', max_depth=7,\n",
    "            min_samples_split=15, min_samples_leaf=8,\n",
    "            n_estimators=300, random_state=42, n_jobs=-1)),\n",
    "    ])\n",
    "\n",
    "    s_svm_pipe = Pipeline([\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('clip', FunctionTransformer(ensure_nonnegative)),\n",
    "        ('nmf', NMF(n_components=40, random_state=42, max_iter=5000)),\n",
    "        ('model', MultiOutputRegressor(SVR(C=10, epsilon=0.1, kernel='rbf'))),\n",
    "    ])\n",
    "\n",
    "    # Models to test with their scalers\n",
    "    synergy_models = {\n",
    "        'S LinearRegression': {'pipe': s_lr_pipe, 'y_train': lr_y_train, 'y_test': lr_y_test, 'scaler': lr_y_scaler},\n",
    "        'S RandomForestRegressor': {'pipe': s_rf_pipe, 'y_train': y_train_scaled, 'y_test': y_test_scaled, 'scaler': y_scaler},\n",
    "        'S SupportVectorRegression': {'pipe': s_svm_pipe, 'y_train': y_train_scaled, 'y_test': y_test_scaled, 'scaler': y_scaler}\n",
    "    }\n",
    "\n",
    "    for model_name, model_config in synergy_models.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"  Starting model: {model_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        base_pipe = model_config['pipe']\n",
    "        y_train_full = model_config['y_train']\n",
    "        y_test_use = model_config['y_test']\n",
    "        scaler = model_config['scaler']\n",
    "        \n",
    "        for train_size_pct in train_sizes:\n",
    "\n",
    "            n_samples = int(len(x_train) * train_size_pct)\n",
    "            x_train_subset = x_train[:n_samples]\n",
    "            y_train_subset = y_train_full[:n_samples]\n",
    "            \n",
    "            print(f\"\\n  Training Size: {train_size_pct*100:.0f}% ({n_samples} samples)\")\n",
    "            \n",
    "            for n_comp in n_components_list:\n",
    "                print(f\"    n_components = {n_comp}...\", end=\" \")\n",
    "                \n",
    "                # Clone and configure pipeline\n",
    "                pipe = clone(base_pipe)\n",
    "                pipe.named_steps['nmf'].n_components = n_comp\n",
    "                \n",
    "                # Train\n",
    "                train_start = time.time()\n",
    "                pipe.fit(x_train_subset, y_train_subset)\n",
    "                train_time = time.time() - train_start\n",
    "                \n",
    "                # Predict\n",
    "                y_pred_scaled = pipe.predict(x_test)\n",
    "                \n",
    "                # Transform back to original scale\n",
    "                y_pred_original = scaler.inverse_transform(y_pred_scaled)\n",
    "                y_test_original = scaler.inverse_transform(y_test_scaled)\n",
    "                \n",
    "                # Metrics on original scale\n",
    "                rmse = np.sqrt(mean_squared_error(y_test_original, y_pred_original))\n",
    "                r2 = r2_score(y_test_original, y_pred_original)\n",
    "                \n",
    "                all_training_results.append({\n",
    "                    'Subject': subject,\n",
    "                    'Model': model_name,\n",
    "                    'Train_Size_Pct': train_size_pct,\n",
    "                    'Train_Size_Samples': n_samples,\n",
    "                    'n_components': n_comp,\n",
    "                    'RMSE': rmse,\n",
    "                    'R2': r2,\n",
    "                    'Train_Time': train_time\n",
    "                })\n",
    "                \n",
    "                print(f\"RMSE={rmse:.4f}, R²={r2:.4f}, Time={train_time:.2f}s\") \n",
    "\n",
    "training_df_all = pd.DataFrame(all_training_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RAW TRAINING DATA (ALL SUBJECTS)\")\n",
    "print(\"=\"*80)\n",
    "print(training_df_all.head(20))\n",
    "\n",
    "# Calculate AVERAGE across all subjects\n",
    "training_df = training_df_all.groupby(['Model', 'Train_Size_Pct', 'n_components']).agg({\n",
    "    'Train_Size_Samples': 'mean',\n",
    "    'RMSE': ['mean', 'std'],\n",
    "    'R2': ['mean', 'std'],\n",
    "    'Train_Time': ['mean', 'std']\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "training_df.columns = ['Model', 'Train_Size_Pct', 'n_components', \n",
    "                       'Train_Size_Samples', \n",
    "                       'RMSE', 'RMSE_std', \n",
    "                       'R2', 'R2_std', \n",
    "                       'Train_Time', 'Train_Time_std']\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AVERAGED TRAINING EFFICIENCY (ACROSS ALL 7 SUBJECTS)\")\n",
    "print(\"=\"*80)\n",
    "print(training_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43789542",
   "metadata": {},
   "source": [
    "Computational Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab4e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Synergy LinearRegression\n",
    "ns_lr_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', MultiOutputRegressor(LinearRegression()))\n",
    "])\n",
    "ns_lr_rmse, ns_lr_r2 = results(ns_lr_pipe, x_train, x_test, lr_y_train, lr_y_test, lr_y_scaler)\n",
    "\n",
    "# Synergy LinearRegression\n",
    "s_lr_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('shift', FunctionTransformer(ensure_nonnegative)),\n",
    "    ('nmf', NMF(n_components = 48, random_state = 42, max_iter = 5000, init='nndsvda')),\n",
    "    ('model', MultiOutputRegressor(LinearRegression()))\n",
    "])\n",
    "s_lr_rmse, s_lr_r2 = results(s_lr_pipe, x_train, x_test, lr_y_train, lr_y_test, lr_y_scaler)\n",
    "\n",
    "# Non-Synergy RandomForestRegressor\n",
    "ns_rf_pipe = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('model', RandomForestRegressor(\n",
    "        max_features = 'sqrt',\n",
    "        max_depth = 7,\n",
    "        min_samples_split = 15,\n",
    "        min_samples_leaf = 8,\n",
    "        n_estimators = 300,\n",
    "        random_state = 42,\n",
    "        n_jobs=-1)),\n",
    "])\n",
    "ns_rf_rmse, ns_rf_r2 = results(ns_rf_pipe, x_train, x_test, y_train, y_test, y_scaler)\n",
    "\n",
    "# Synergy RandomForestRegressor\n",
    "s_rf_pipe = Pipeline([\n",
    "    ('scaler', MinMaxScaler(feature_range = (0, 1))),\n",
    "    ('clip', FunctionTransformer(ensure_nonnegative)),\n",
    "    ('nmf', NMF(n_components = 48, random_state = 42, max_iter = 5000, init='nndsvda')),\n",
    "    ('model', RandomForestRegressor(\n",
    "        max_features = 'sqrt',\n",
    "        max_depth = 7,\n",
    "        min_samples_split = 15,\n",
    "        min_samples_leaf = 8,\n",
    "        n_estimators = 300,\n",
    "        random_state = 42,\n",
    "        n_jobs=-1)),\n",
    "])\n",
    "s_rf_rmse, s_rf_r2 = results(s_rf_pipe, x_train, x_test, y_train, y_test, y_scaler)\n",
    "\n",
    "# Non-Synergy SupportVectorRegression\n",
    "ns_svm_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', MultiOutputRegressor(SVR(C = 10, epsilon = 0.1, kernel = 'rbf'))),\n",
    "])\n",
    "ns_svm_rmse, ns_svm_r2 = results(ns_svm_pipe, x_train, x_test, y_train, y_test, y_scaler)\n",
    "\n",
    "# Synergy SupportVectorRegression\n",
    "s_svm_pipe = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('clip', FunctionTransformer(ensure_nonnegative)),\n",
    "    ('nmf', NMF(n_components = 40, random_state = 42, max_iter = 5000)),\n",
    "    ('model', MultiOutputRegressor(SVR(C = 10, epsilon = 0.1, kernel = 'rbf'))),\n",
    "])\n",
    "s_svm_rmse, s_svm_r2 = results(s_svm_pipe, x_train, x_test, y_train, y_test, y_scaler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
